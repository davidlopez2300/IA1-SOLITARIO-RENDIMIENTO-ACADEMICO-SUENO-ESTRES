

# Proyecto: An√°lisis y Predicci√≥n de Rendimiento Acad√©mico: El Impacto de los H√°bitos Diarios

### Identificaci√≥n del proyecto

* **Curso:** Inteligencia Artificial I ‚Äì 2025-2 C1
* **Equipo:** Solitario
* **Integrantes:**

  * Juan David Lopez Ruiz ‚Äì C√≥digo UIS: 2180645
  

---

## Descripci√≥n de los Datos a Usar

**Dataset Principal:** `student_habits_performance.csv`(https://www.kaggle.com/datasets/jayaantanaath/student-habits-vs-academic-performance?resource=download)


**Video:**`Proyecto: An√°lisis y Predicci√≥n de Rendimiento Acad√©mico`(https://youtu.be/0MBABNBxmKU)

* **Variables Clave:** El conjunto de datos consta de **16 columnas** que incluyen variables cuantitativas (ej. `study_hours_per_day`, `sleep_hours`, `social_media_hours`) y variables categ√≥ricas u ordinales (ej. `diet_quality`, `part_time_job`).
* **Cantidad de Datos:** Contiene **1000 filas** sin datos faltantes, lo que lo prepara √≥ptimamente para aplicaciones de an√°lisis y Machine Learning.
* **Variable Objetivo (Transformada):** `Performance_Level` (Clasificaci√≥n Multiclase: **Bajo (0), Medio (1), Alto (2)**).

---

## Preguntas a Responder

### Antes del EDA (Conceptual y Metodol√≥gico)

| Aspecto | Descripci√≥n Actualizada |
| :--- | :--- |
| **Problema y Relevancia** | El bajo rendimiento est√° ligado a una gesti√≥n ineficiente de factores del d√≠a a d√≠a (sue√±o, uso de pantallas, dieta). Predecir el rendimiento en tres niveles (Bajo, Medio, Alto) permite dise√±ar **estrategias de intervenci√≥n focalizadas** para cada grupo, maximizando el apoyo estudiantil. |
| **Objetivo del An√°lisis** | **Fase 1 (EDA):** Identificar patrones de correlaci√≥n entre h√°bitos diarios y el rendimiento. **Fase 2 (ML):** Construir un **Modelo de Clasificaci√≥n Multiclase** (Random Forest) robusto para predecir si un estudiante caer√° en el nivel Bajo, Medio o Alto, permitiendo la **intervenci√≥n temprana**. |
| **M√©tricas o Indicadores** | Se emplean m√©tricas de clasificaci√≥n multiclase: **Accuracy** (Precisi√≥n General) y **Reporte de Clasificaci√≥n (Precision, Recall, F1-score)** por clase. La optimizaci√≥n busca mejorar el F1-score en la clase **Medio (1)**, que es la m√°s dif√≠cil de predecir. |
| **Motivaci√≥n de la Elecci√≥n** | Elegimos este enfoque porque provee una herramienta **accionable** para la comunidad acad√©mica. La clasificaci√≥n multiclase es m√°s √∫til que la binaria para la gesti√≥n de recursos y la orientaci√≥n personalizada del estudiante. |

---

# Metodol√≥gica del Proyecto: Predicci√≥n del Rendimiento Acad√©mico

Este documento resume las fases clave y las decisiones metodol√≥gicas tomadas en el desarrollo del modelo de Machine Learning para predecir el rendimiento acad√©mico (Bajo, Medio, Alto) a partir de los h√°bitos diarios del estudiante.

---

### I.  Definici√≥n del Problema y Preparaci√≥n de Datos

Se opt√≥ por un enfoque de **Clasificaci√≥n Multiclase** por su **utilidad pr√°ctica** para la intervenci√≥n acad√©mica, siendo m√°s valioso conocer la categor√≠a de riesgo (Bajo/Medio/Alto) que un puntaje exacto.

1.  **Variable Objetivo:** La variable continua `exam_score` se transform√≥ en `performance_level` (0, 1, 2) usando los **percentiles 33% y 66%** para asegurar un balance equitativo de clases.
2.  **Calidad de Datos:** Se confirm√≥ la ausencia total de valores nulos y se procedi√≥ a la eliminaci√≥n del identificador `student_id`.
3.  **Preprocesamiento:** Se aplic√≥ **One-Hot Encoding (OHE)** a todas las variables categ√≥ricas. Los datos fueron divididos en conjuntos de Entrenamiento y Prueba (70/30) utilizando `stratify=y` para mantener el balance de clases en ambos subconjuntos.

---

### II.  An√°lisis Exploratorio de Datos (EDA)

El an√°lisis visual confirm√≥ las hip√≥tesis iniciales sobre la relaci√≥n entre h√°bitos y rendimiento:

* **Impacto Positivo:** El **Heatmap** y los diagramas de caja confirmaron que **`study_hours_per_day`** y **`attendance_percentage`** son los predictores positivos m√°s fuertes.
* **Factores de Riesgo:** El **Diagrama de Dispersi√≥n** demostr√≥ que los estudiantes de rendimiento **Bajo (0)** se agrupan consistentemente en √°reas de **Bajas Horas de Estudio y Altas Horas de Redes Sociales**.
* **Zona de Error:** La clase **Medio (1)** se localiza en la zona central de superposici√≥n, siendo el principal desaf√≠o para la clasificaci√≥n.

---

### III.  Modelado y Optimizaci√≥n

Se eligi√≥ el **Random Forest Classifier** por su robustez ante datos mixtos y su capacidad de interpretar la importancia de las caracter√≠sticas.

#### A. Flujo de Modelado

| Paso | Prop√≥sito |
| :--- | :--- |
| **Modelo Base** | Entrenado con par√°metros por defecto (`n_estimators=100`) para establecer un rendimiento inicial (Accuracy inicial **~0.7867**). |
| **Optimizaci√≥n** | Se implement√≥ **Grid Search (`GridSearchCV`)** para realizar una b√∫squeda exhaustiva de la mejor combinaci√≥n de hiperpar√°metros (`max_depth`, `n_estimators`, etc.) y maximizar el rendimiento general y el F1-score de la clase **Medio (1)**. |
| **Validaci√≥n** | El modelo optimizado fue sometido a an√°lisis de **Matriz de Confusi√≥n** y **Curvas ROC/AUC** para medir su capacidad discriminatoria y diagnosticar fallos en la predicci√≥n de la clase **Medio (1)**. |

#### B. Interpretaci√≥n de Resultados

* **Matriz de Confusi√≥n:** Revel√≥ que el error m√°s frecuente es clasificar err√≥neamente a estudiantes **Medios (1)** como **Bajos (0)**, lo cual es cr√≠tico pero esperable dada la ambig√ºedad de la zona central.
* **Importancia de Variables:** Los principales impulsores predictivos del modelo son:
    1.  **`study_hours_per_day`** (Mayor influencia).
    2.  **`social_media_hours`** (Impacto negativo).
    3.  **`sleep_hours`** (Factor clave de bienestar).

Esta metodolog√≠a asegura que el modelo no solo sea preciso, sino tambi√©n **interpretable**, ofreciendo justificaci√≥n clara para las estrategias de intervenci√≥n acad√©mica.

---

## IV. Aprendizaje No Supervisado: Descubrimiento de Patrones Latentes

Una vez construidos y evaluados los modelos supervisados de predicci√≥n del rendimiento acad√©mico, se desarroll√≥ una fase complementaria de **Aprendizaje No Supervisado**, cuyo objetivo fue identificar **patrones naturales** en los estudiantes sin utilizar etiquetas. Esta fase no pretende predecir rendimiento, sino **descubrir perfiles** que permitan entender mejor c√≥mo se agrupan los estudiantes seg√∫n sus h√°bitos, sue√±o y bienestar general.

### 1. Prop√≥sito del An√°lisis No Supervisado

El objetivo principal fue determinar si las variables de h√°bitos diarios y bienestar son capaces de formar **clusters coherentes**, es decir, grupos de estudiantes con caracter√≠sticas similares que puedan relacionarse indirectamente con los niveles de rendimiento acad√©mico observados.

Espec√≠ficamente, se busc√≥:

- Identificar perfiles estudiantiles sin utilizar la variable objetivo.
- Analizar si h√°bitos de estudio, sue√±o y factores mentales generan separaciones naturales.
- Comparar diferentes algoritmos de clustering para evaluar estabilidad y calidad de los grupos.
- Visualizar estos patrones utilizando reducci√≥n de dimensionalidad.

---

## 2. Preprocesamiento y Selecci√≥n de Caracter√≠sticas

Para esta fase, se trabaj√≥ √∫nicamente sobre **variables num√©ricas**, ya que los algoritmos de clustering requieren espacios vectoriales formales.  
Los pasos aplicados fueron:

1. Eliminaci√≥n de `student_id` y otras columnas irrelevantes.  
2. Selecci√≥n de caracter√≠sticas num√©ricas del dataset.  
3. **Estandarizaci√≥n con `StandardScaler`** para ubicar todas las variables en la misma escala y evitar sesgos por magnitud.  
4. Preparaci√≥n de una matriz final (`X_scaled`) utilizada por todos los algoritmos.

---

## 3. Algoritmos de Clustering Utilizados

Se implementaron tres de los m√©todos de agrupamiento m√°s utilizados y complementarios entre s√≠:

### üîπ **3.1 K-Means Clustering**

- Se utiliz√≥ el **M√©todo del Codo (Elbow Method)** para estimar el n√∫mero √≥ptimo de clusters.
- El modelo fue entrenado con el valor de k m√°s adecuado seg√∫n la forma de curva de inercia.
- Se calcul√≥ el **Silhouette Score**, que mide la cohesi√≥n y separaci√≥n entre grupos.

Este enfoque permite descubrir agrupaciones compactas y bien definidas.

---

### üîπ **3.2 DBSCAN**

- Se aplic√≥ `DBSCAN(eps=1, min_samples=5)`.
- Identifica grupos basados en densidad, permitiendo detectar:
  -En la practica del ejercicio detecto mayormente ruido.

Es especialmente √∫til porque no requiere especificar el n√∫mero de clusters y detecta ruido naturalmente.

---

### üîπ **3.3 Agglomerative Clustering (Jer√°rquico)**

- Permite modelar la estructura jer√°rquica de los datos y comparar c√≥mo se agrupan los estudiantes desde niveles generales hasta segmentos espec√≠ficos.

Este m√©todo complementa a K-Means y DBSCAN al analizar c√≥mo los grupos pueden formarse de manera ascendente a partir de pares de observaciones.

---

## 4. Evaluaci√≥n de la Calidad del Clustering

Para cada modelo se utiliz√≥:

- **Silhouette Score**, que indica qu√© tan bien separados est√°n los clusters.  
- Comparaci√≥n entre m√©todos para evaluar consistencia de patrones.  

Gracias a estas m√©tricas se verific√≥ que los grupos formados no eran aleatorios y reflejaban diferencias reales en h√°bitos diarios.

---

## 5. Reducci√≥n de Dimensionalidad para Visualizaci√≥n

Dado que el dataset contiene m√∫ltiples variables, se aplicaron t√©cnicas para proyectar los datos en 2 dimensiones y facilitar la interpretaci√≥n visual.

### üî∏ **PCA ‚Äì An√°lisis de Componentes Principales**

- Reduce la dimensionalidad preservando la mayor parte de la varianza.
- Permite visualizar los clusters de manera lineal.


### üî∏ **t-SNE ‚Äì Proyecci√≥n No Lineal**

- Proyecta datos en 2D preservando relaciones locales.
- Muestra agrupamientos complejos que no son visibles con PCA.









